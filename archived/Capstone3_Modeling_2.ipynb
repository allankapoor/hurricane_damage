{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ab4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081b6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "861414ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = ('/Users/allankapoor/Documents/Springboard/structure_damage/')\n",
    "train_path = os.path.join(DIR, 'data', 'train_another')\n",
    "val_path = os.path.join(DIR, 'data', 'validation_another')\n",
    "test_path = os.path.join(DIR, 'data', 'test_another')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd13e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = (128, 128)\n",
    "batch_size = 100\n",
    "\n",
    "# specify training image transformations \n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# specify validation image transformations (rescale only)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# keras generator for training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "# keras generator for validation data\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bcd5b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffered prefetching (?)\n",
    "train_ds = train_ds.prefetch(buffer_size=32)\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e9b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nn_training(history):\n",
    "    \n",
    "    '''Given model training history, plots validation accuracy and loss'''\n",
    "    \n",
    "    # plot history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # plot history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6dec0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model2(input_shape, num_classes):\n",
    "    \n",
    "    '''CNN model architecture with max pooling + dropout layers'''\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Image augmentation\n",
    "    #x = data_augmentation(inputs)\n",
    "    # rescaling\n",
    "    x = Rescaling(1.0 / 255)(inputs)\n",
    "    \n",
    "    # convolution (with max pooling)\n",
    "    x = Conv2D(32, kernel_size=5, strides=2, padding=\"same\")(x) # put activation in here\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', data_format=None)(x) \n",
    "    x = BatchNormalization()(x) # why?\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', data_format=None)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', data_format=None)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    #flatten\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    #dense layers (with dropout to avoid overfitting)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    # output layer\n",
    "    output = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    mod = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3ccbcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "# patient early stopping\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)\n",
    "\n",
    "mc = ModelCheckpoint('models/Model2/best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\")]\n",
    "\n",
    "# Instantiate model\n",
    "model2 = generate_model2(input_shape=(128,128,3), num_classes=2)\n",
    "\n",
    "# Compile model\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb9ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model (not working?)\n",
    "results2 = model2.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100, # num_samples//batch_size\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=20) # num_samples//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38948ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14e7c8c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14e7c8c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.8292WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14e7fa8b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x14e7fa8b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 21s 64ms/step - loss: 0.3620 - accuracy: 0.8294 - val_loss: 4.8867 - val_accuracy: 0.5060\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.1478 - accuracy: 0.9399 - val_loss: 3.2312 - val_accuracy: 0.4990\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.1167 - accuracy: 0.9569 - val_loss: 2.2089 - val_accuracy: 0.5725\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.1020 - accuracy: 0.9615 - val_loss: 3.9611 - val_accuracy: 0.5340\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0829 - accuracy: 0.9696 - val_loss: 4.0434 - val_accuracy: 0.5585\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0596 - accuracy: 0.9792 - val_loss: 3.4738 - val_accuracy: 0.5660\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0541 - accuracy: 0.9802 - val_loss: 3.4538 - val_accuracy: 0.5195\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 20s 62ms/step - loss: 0.0504 - accuracy: 0.9824 - val_loss: 3.0458 - val_accuracy: 0.5765\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 3.4609 - val_accuracy: 0.4900\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0392 - accuracy: 0.9842 - val_loss: 3.2464 - val_accuracy: 0.5400\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 3.0061 - val_accuracy: 0.6330\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 4.0758 - val_accuracy: 0.5025\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 20s 62ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 2.7009 - val_accuracy: 0.7170\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 3.6155 - val_accuracy: 0.6660\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 4.8803 - val_accuracy: 0.6725\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0348 - accuracy: 0.9888 - val_loss: 5.7272 - val_accuracy: 0.6445\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0327 - accuracy: 0.9906 - val_loss: 5.0151 - val_accuracy: 0.5445\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.0212 - accuracy: 0.9940 - val_loss: 5.8992 - val_accuracy: 0.5385\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0246 - accuracy: 0.9935 - val_loss: 3.6758 - val_accuracy: 0.6430\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 5.2768 - val_accuracy: 0.5745\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 5.5890 - val_accuracy: 0.6710\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0309 - accuracy: 0.9927 - val_loss: 5.9741 - val_accuracy: 0.6905\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 6.3731 - val_accuracy: 0.7005\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0315 - accuracy: 0.9927 - val_loss: 4.5194 - val_accuracy: 0.7165\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 20s 62ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 4.8285 - val_accuracy: 0.5685\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0150 - accuracy: 0.9937 - val_loss: 4.7861 - val_accuracy: 0.7155\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 7.2562 - val_accuracy: 0.7280\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 8.0748 - val_accuracy: 0.6715\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 20s 62ms/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 5.5662 - val_accuracy: 0.6655\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 7.4405 - val_accuracy: 0.7020\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 3.7125 - val_accuracy: 0.6945\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 20s 62ms/step - loss: 0.0186 - accuracy: 0.9922 - val_loss: 4.4086 - val_accuracy: 0.7015\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.0216 - accuracy: 0.9950 - val_loss: 5.5595 - val_accuracy: 0.7030\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 8.3835 - val_accuracy: 0.7240\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 3.2677 - val_accuracy: 0.7460\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0211 - accuracy: 0.9941 - val_loss: 7.9810 - val_accuracy: 0.5690\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 8.7777 - val_accuracy: 0.7335\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 8.4295 - val_accuracy: 0.7280\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0250 - accuracy: 0.9960 - val_loss: 7.2971 - val_accuracy: 0.7175\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 20s 62ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 12.2931 - val_accuracy: 0.7325\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 7.9292 - val_accuracy: 0.6415\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.0171 - accuracy: 0.9969 - val_loss: 12.9543 - val_accuracy: 0.5455\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 8.9291 - val_accuracy: 0.6930\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 6.1012 - val_accuracy: 0.6900\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 6.8555 - val_accuracy: 0.7190\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 9.8501 - val_accuracy: 0.6540\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 8.7212 - val_accuracy: 0.7325\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 12.2278 - val_accuracy: 0.7150\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 11.6007 - val_accuracy: 0.7405\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 7.7856 - val_accuracy: 0.7475\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "results2 = model2.fit(\n",
    "    train_ds,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de61730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ffa73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_TL_model(input_shape, num_classes):\n",
    "    \n",
    "    weights = 'imagenet'\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    #what does include_top=False remove?\n",
    "    base_model = ResNet50(include_top=False, weights=weights, input_shape=(128, 128, 3))\n",
    "\n",
    "    #freezing the resnet layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #these convolution layers come before the resnet layers\n",
    "    x = Conv2D(32, (5, 5), strides=2, padding='same', activation='relu', input_shape=(128, 128, 3))(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', data_format=None)(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', data_format=None)(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', data_format=None)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    base_resnet = base_model(inputs)\n",
    "    base_resnet = Flatten()(base_resnet)\n",
    "\n",
    "    concated_layers = Concatenate()([x, base_resnet])\n",
    "\n",
    "    # dense layers come after the resnet layers\n",
    "    # dropout to reduce overfit\n",
    "    concated_layers = Dense(1024, activation='relu')(concated_layers)\n",
    "    concated_layers = Dropout(0.3)(concated_layers)\n",
    "    concated_layers = Dense(512, activation='relu')(concated_layers)\n",
    "    concated_layers = Dropout(0.2)(concated_layers)\n",
    "    concated_layers = Dense(256, activation='relu')(concated_layers)\n",
    "    concated_layers = Dropout(0.1)(concated_layers)\n",
    "    \n",
    "    # output layer\n",
    "    output = Dense(num_classes, activation='softmax')(concated_layers)\n",
    "\n",
    "    mod = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71303158",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\")]\n",
    "\n",
    "# Instantiate model\n",
    "TL_model = generate_TL_model(input_shape=(128,128,3), num_classes=2)\n",
    "\n",
    "# Compile model\n",
    "TL_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5be5277d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14815d310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14815d310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - ETA: 0s - loss: 2.1519 - accuracy: 0.8112WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x17e513160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x17e513160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 256s 808ms/step - loss: 2.1480 - accuracy: 0.8114 - val_loss: 4.5998 - val_accuracy: 0.6925\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 248s 789ms/step - loss: 0.2825 - accuracy: 0.9302 - val_loss: 3.0082 - val_accuracy: 0.7205\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 234s 745ms/step - loss: 0.0992 - accuracy: 0.9642 - val_loss: 3.3073 - val_accuracy: 0.7340\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 230s 733ms/step - loss: 0.0790 - accuracy: 0.9678 - val_loss: 4.1167 - val_accuracy: 0.7255\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 235s 751ms/step - loss: 0.0793 - accuracy: 0.9706 - val_loss: 4.1591 - val_accuracy: 0.7245\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 240s 766ms/step - loss: 0.0619 - accuracy: 0.9802 - val_loss: 3.6098 - val_accuracy: 0.7295\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 242s 771ms/step - loss: 0.0400 - accuracy: 0.9855 - val_loss: 6.3706 - val_accuracy: 0.7200\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 239s 761ms/step - loss: 0.0489 - accuracy: 0.9835 - val_loss: 4.1173 - val_accuracy: 0.7325\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 232s 742ms/step - loss: 0.0389 - accuracy: 0.9865 - val_loss: 6.7645 - val_accuracy: 0.7250\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 235s 751ms/step - loss: 0.0350 - accuracy: 0.9880 - val_loss: 6.1548 - val_accuracy: 0.6655\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "TL_model_fit = TL_model.fit(train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c5744",
   "metadata": {},
   "source": [
    "### Now trying with image augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cf0b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\")]\n",
    "\n",
    "# Instantiate model\n",
    "TL_model_2 = generate_TL_model(input_shape=(128,128,3), num_classes=2)\n",
    "\n",
    "# Compile model\n",
    "TL_model_2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efc70d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x169de7280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x169de7280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 16:13:54.697454: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-11-27 16:13:54.698013: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 1.9756 - accuracy: 0.7844WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x3afc90040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x3afc90040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "100/100 [==============================] - 237s 2s/step - loss: 1.9661 - accuracy: 0.7852 - val_loss: 0.3764 - val_accuracy: 0.9300\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 246s 2s/step - loss: 0.5418 - accuracy: 0.9185 - val_loss: 0.1414 - val_accuracy: 0.9550\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 254s 3s/step - loss: 0.2379 - accuracy: 0.9429 - val_loss: 0.1834 - val_accuracy: 0.9325\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 255s 3s/step - loss: 0.1659 - accuracy: 0.9468 - val_loss: 0.1000 - val_accuracy: 0.9630\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 278s 3s/step - loss: 0.1290 - accuracy: 0.9600 - val_loss: 0.0951 - val_accuracy: 0.9655\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 235s 2s/step - loss: 0.1275 - accuracy: 0.9553 - val_loss: 0.0834 - val_accuracy: 0.9675\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 268s 3s/step - loss: 0.0814 - accuracy: 0.9697 - val_loss: 0.0853 - val_accuracy: 0.9690\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 312s 3s/step - loss: 0.0620 - accuracy: 0.9761 - val_loss: 0.0926 - val_accuracy: 0.9650\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 392s 4s/step - loss: 0.0670 - accuracy: 0.9747 - val_loss: 0.0930 - val_accuracy: 0.9660\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 240s 2s/step - loss: 0.0648 - accuracy: 0.9763 - val_loss: 0.0942 - val_accuracy: 0.9690\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "TL_model_fit_2 = TL_model_2.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100, # num_samples//batch_size\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=20) # num_samples//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30e1631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env_2",
   "language": "python",
   "name": "tf_env_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
